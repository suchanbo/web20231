{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d3257a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.brain as fob\n",
    "import fiftyone.brain.internal.models as fbm\n",
    "import numpy as np\n",
    "\n",
    "model = fbm.load_model(\"simple-resnet-cifar10\")\n",
    "\n",
    "def find_unique(dataset_dir,sub_thresh=0.01,subset_files=None):\n",
    "\ttry:\n",
    "\t\tfo.core.dataset.delete_non_persistent_datasets()\n",
    "\texcept:\n",
    "\t\tpass\n",
    "\tdataset = fo.Dataset.from_dir(dataset_dir=dataset_dir,dataset_type=fo.types.ImageDirectory,name='temp1',)\n",
    "\tif subset_files is not None:\n",
    "\t\tfor sample in dataset:\n",
    "\t\t\tif sample.filename not in subset_files:\n",
    "\t\t\t\tdataset.delete_samples(sample.id)\n",
    "\tembeddings = dataset.compute_embeddings(model, batch_size=16)\n",
    "\tresults = fob.compute_similarity(dataset, embeddings=embeddings, brain_key=\"img_sim\")\n",
    "\tuniques,threshes=[],[]\n",
    "\tfor thresh in np.arange(0.01,1,0.01):\n",
    "\t    try:\n",
    "\t        results.find_duplicates(thresh=thresh)\n",
    "\t        print('Unique samples found:'+ str(len(results.unique_ids)) + ' at thresh='+str(thresh))\n",
    "\t        uniques.append(len(results.unique_ids))\n",
    "\t        threshes.append(thresh)\n",
    "\t        if len(uniques)>1:\n",
    "\t        \tif ((uniques[-2]-uniques[-1])/len(dataset))<(sub_thresh*0.5):\n",
    "\t        \t\tbreak\n",
    "\t    except:\n",
    "\t        pass\n",
    "\tarr=np.round(np.diff(np.flip(uniques))/len(dataset),4)>sub_thresh\n",
    "\tprint(\"the values in arr:\",arr)\n",
    "\tcont=len(uniques)-1\n",
    "\tfound=False\n",
    "\tfor j in range(cont,0,-1):\n",
    "\t    for i in range(len(arr)):\n",
    "\t        if i+j==len(arr)+1:\n",
    "\t            break\n",
    "\t        if arr[i:i+j].all():\n",
    "\t            idx=i\n",
    "\t            found=True\n",
    "\t            break\n",
    "\t    if found:\n",
    "\t    \tcont=j\n",
    "\t    \tbreak\n",
    "\ttry:\n",
    "\t\tidx\n",
    "\texcept NameError:\t\t\n",
    "\t\tif len(uniques)>1:\n",
    "\t\t\tif ((uniques[-2]-uniques[-1])/len(dataset))<(sub_thresh*0.5):\n",
    "\t\t\t\tidx = len(uniques)-1\n",
    "\t\t\t\t\t\n",
    "\tthresh=np.flip(threshes)[idx]\n",
    "\tresults.find_duplicates(thresh=thresh)\n",
    "\tprint('\\nThreshold fixed at:'+str(thresh)+' at continuity count of '+str(cont))\n",
    "\tprint('Total Unique samples collected:', len(results.unique_ids))\n",
    "\tunique_fname=[sample.filename for sample in dataset if sample.id in results.unique_ids]\n",
    "\tdataset.delete()\n",
    "\treturn unique_fname\n",
    "\n",
    "\n",
    "def main():\n",
    "\tfrom find_unique import find_unique\n",
    "\t#dataset_dir=r'\\\\glbmiaas01cf021\\\\BMGF\\\\DATA\\\\ARC_DATA\\\\main_test\\\\FAM-025-0004-2\\\\New folder'\n",
    "\n",
    "\t#putting example dataset\n",
    "\tdataset_dir=r'C:\\Users\\320199927\\Desktop\\DATA4exp\\New folder'\n",
    "\tunique_files=find_unique(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a48612b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec65e15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7f356df8c3538e96c7b54691155e2034a237f889adf626032358aa6b92eae161"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
